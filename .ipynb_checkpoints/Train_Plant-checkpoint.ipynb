{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af44c856-71b6-44f7-98b1-9d4accd09cb2",
   "metadata": {},
   "source": [
    "### IMPORTING LIBARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498dcc73-8288-4f31-8dcf-fed9c96016a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015cc9a-fe16-476b-8fd0-44f49390b319",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING\n",
    "### TRAINING IMAGE PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb2903fc-63bc-4794-a1cf-550617cfd1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70295 files belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763fd235-b2b1-4450-b5c1-3426f30918f5",
   "metadata": {},
   "source": [
    "### VALIDATION IMAGE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ab711bb-4374-4796-b041-c33ddbe47b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17572 files belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e4e1978-9a8f-4e01-8d7b-372e9aae0b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 38), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afdb15a5-61c0-4d35-a670-bae90261a85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   ...\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]]\n",
      "\n",
      "  [[  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   ...\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]]\n",
      "\n",
      "  [[  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   ...\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   ...\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]]\n",
      "\n",
      "  [[  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   ...\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]]\n",
      "\n",
      "  [[  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   ...\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]\n",
      "   [  0.     0.     0.  ]]]\n",
      "\n",
      "\n",
      " [[[148.25 144.25 145.25]\n",
      "   [144.   140.   141.  ]\n",
      "   [147.25 143.25 144.25]\n",
      "   ...\n",
      "   [177.   175.   178.  ]\n",
      "   [184.25 182.25 185.25]\n",
      "   [183.25 181.25 184.25]]\n",
      "\n",
      "  [[138.75 134.75 135.75]\n",
      "   [147.75 143.75 144.75]\n",
      "   [143.5  139.5  140.5 ]\n",
      "   ...\n",
      "   [175.75 173.75 176.75]\n",
      "   [178.5  176.5  179.5 ]\n",
      "   [176.25 174.25 177.25]]\n",
      "\n",
      "  [[147.   143.   144.  ]\n",
      "   [143.5  139.5  140.5 ]\n",
      "   [144.75 140.75 141.75]\n",
      "   ...\n",
      "   [180.   178.   181.  ]\n",
      "   [181.75 179.75 182.75]\n",
      "   [180.75 178.75 181.75]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[124.25 116.25 114.25]\n",
      "   [127.25 119.25 117.25]\n",
      "   [128.5  120.5  118.5 ]\n",
      "   ...\n",
      "   [163.5  159.5  160.5 ]\n",
      "   [161.75 157.75 158.75]\n",
      "   [164.5  160.5  161.5 ]]\n",
      "\n",
      "  [[128.75 120.75 118.75]\n",
      "   [130.   122.   120.  ]\n",
      "   [124.75 116.75 114.75]\n",
      "   ...\n",
      "   [160.25 156.25 157.25]\n",
      "   [163.25 159.25 160.25]\n",
      "   [165.25 161.25 162.25]]\n",
      "\n",
      "  [[124.   116.   114.  ]\n",
      "   [123.5  115.5  113.5 ]\n",
      "   [118.5  110.5  108.5 ]\n",
      "   ...\n",
      "   [160.5  156.5  157.5 ]\n",
      "   [168.25 164.25 165.25]\n",
      "   [167.75 163.75 164.75]]]\n",
      "\n",
      "\n",
      " [[[141.   173.   124.  ]\n",
      "   [135.5  167.5  118.5 ]\n",
      "   [135.   167.   118.  ]\n",
      "   ...\n",
      "   [120.   159.    77.5 ]\n",
      "   [110.25 144.25  69.25]\n",
      "   [127.5  157.5   87.  ]]\n",
      "\n",
      "  [[147.25 179.25 132.25]\n",
      "   [139.25 171.25 124.25]\n",
      "   [137.75 169.75 122.75]\n",
      "   ...\n",
      "   [122.75 162.    78.75]\n",
      "   [111.5  145.75  68.25]\n",
      "   [130.25 160.25  87.25]]\n",
      "\n",
      "  [[165.   193.75 150.5 ]\n",
      "   [152.75 181.5  138.25]\n",
      "   [147.   175.75 132.5 ]\n",
      "   ...\n",
      "   [107.75 147.5   61.75]\n",
      "   [103.75 138.5   58.75]\n",
      "   [128.25 159.25  83.25]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[174.25 201.25 166.25]\n",
      "   [161.   191.   153.  ]\n",
      "   [161.   193.   154.  ]\n",
      "   ...\n",
      "   [ 40.    80.    19.  ]\n",
      "   [ 36.5   77.    12.  ]\n",
      "   [ 37.5   78.75   8.75]]\n",
      "\n",
      "  [[174.25 201.25 166.25]\n",
      "   [163.5  193.5  155.5 ]\n",
      "   [160.5  192.5  153.5 ]\n",
      "   ...\n",
      "   [ 38.    78.    17.  ]\n",
      "   [ 45.    86.    18.5 ]\n",
      "   [ 34.5   76.5    2.5 ]]\n",
      "\n",
      "  [[170.5  197.5  162.5 ]\n",
      "   [162.25 192.25 154.25]\n",
      "   [159.25 191.25 152.25]\n",
      "   ...\n",
      "   [ 37.5   77.5   16.  ]\n",
      "   [ 51.5   93.    23.  ]\n",
      "   [ 44.    86.5    9.  ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[147.   146.   152.  ]\n",
      "   [153.   152.   158.  ]\n",
      "   [148.   147.   153.  ]\n",
      "   ...\n",
      "   [131.75 130.75 136.75]\n",
      "   [129.5  128.5  134.5 ]\n",
      "   [134.75 133.75 139.75]]\n",
      "\n",
      "  [[148.   147.   153.  ]\n",
      "   [146.5  145.5  151.5 ]\n",
      "   [146.   145.   151.  ]\n",
      "   ...\n",
      "   [134.25 133.25 139.25]\n",
      "   [131.75 130.75 136.75]\n",
      "   [132.75 131.75 137.75]]\n",
      "\n",
      "  [[147.5  146.5  152.5 ]\n",
      "   [144.75 143.75 149.75]\n",
      "   [148.25 147.25 153.25]\n",
      "   ...\n",
      "   [135.   134.   140.  ]\n",
      "   [132.75 131.75 137.75]\n",
      "   [131.75 130.75 136.75]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[113.5  111.5  114.5 ]\n",
      "   [113.   111.   114.  ]\n",
      "   [108.   106.   109.  ]\n",
      "   ...\n",
      "   [106.25 101.25 105.25]\n",
      "   [106.5  101.5  105.5 ]\n",
      "   [104.    99.   103.  ]]\n",
      "\n",
      "  [[117.75 115.75 118.75]\n",
      "   [114.25 112.25 115.25]\n",
      "   [108.25 106.25 109.25]\n",
      "   ...\n",
      "   [104.5   99.5  103.5 ]\n",
      "   [107.5  102.5  106.5 ]\n",
      "   [103.    98.   102.  ]]\n",
      "\n",
      "  [[111.25 109.25 112.25]\n",
      "   [115.25 113.25 116.25]\n",
      "   [111.25 109.25 112.25]\n",
      "   ...\n",
      "   [110.   105.   109.  ]\n",
      "   [106.25 101.25 105.25]\n",
      "   [107.25 102.25 106.25]]]\n",
      "\n",
      "\n",
      " [[[159.5  141.5  137.5 ]\n",
      "   [166.   148.   144.  ]\n",
      "   [159.75 141.75 137.75]\n",
      "   ...\n",
      "   [130.   109.   106.  ]\n",
      "   [118.5   97.5   94.5 ]\n",
      "   [119.25  98.25  95.25]]\n",
      "\n",
      "  [[163.25 145.25 141.25]\n",
      "   [159.   141.   137.  ]\n",
      "   [158.5  140.5  136.5 ]\n",
      "   ...\n",
      "   [115.25  94.25  91.25]\n",
      "   [126.5  105.5  102.5 ]\n",
      "   [144.25 123.25 120.25]]\n",
      "\n",
      "  [[157.5  139.5  135.5 ]\n",
      "   [155.25 137.25 133.25]\n",
      "   [163.5  145.5  141.5 ]\n",
      "   ...\n",
      "   [121.25 100.25  97.25]\n",
      "   [104.25  83.25  80.25]\n",
      "   [117.5   96.5   93.5 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[189.75 178.75 172.75]\n",
      "   [191.   180.   174.  ]\n",
      "   [194.   183.   177.  ]\n",
      "   ...\n",
      "   [153.75 136.75 129.75]\n",
      "   [153.25 136.25 129.25]\n",
      "   [148.75 131.75 124.75]]\n",
      "\n",
      "  [[189.   178.   172.  ]\n",
      "   [184.25 173.25 167.25]\n",
      "   [190.   179.   173.  ]\n",
      "   ...\n",
      "   [154.25 137.25 130.25]\n",
      "   [148.75 131.75 124.75]\n",
      "   [149.75 132.75 125.75]]\n",
      "\n",
      "  [[189.   178.   172.  ]\n",
      "   [190.25 179.25 173.25]\n",
      "   [188.   177.   171.  ]\n",
      "   ...\n",
      "   [157.25 140.25 133.25]\n",
      "   [160.   143.   136.  ]\n",
      "   [135.5  118.5  111.5 ]]]\n",
      "\n",
      "\n",
      " [[[107.5   95.5  117.5 ]\n",
      "   [107.    95.   117.  ]\n",
      "   [103.5   91.5  113.5 ]\n",
      "   ...\n",
      "   [135.5  129.5  155.5 ]\n",
      "   [131.75 125.75 151.75]\n",
      "   [131.5  125.5  151.5 ]]\n",
      "\n",
      "  [[110.75  98.75 120.75]\n",
      "   [110.5   98.5  120.5 ]\n",
      "   [110.    98.   120.  ]\n",
      "   ...\n",
      "   [136.25 130.25 156.25]\n",
      "   [138.   132.   158.  ]\n",
      "   [138.25 132.25 158.25]]\n",
      "\n",
      "  [[109.    97.   119.  ]\n",
      "   [108.75  96.75 118.75]\n",
      "   [110.    98.   120.  ]\n",
      "   ...\n",
      "   [134.25 128.25 154.25]\n",
      "   [133.   127.   153.  ]\n",
      "   [131.5  125.5  151.5 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[105.5   96.5  123.5 ]\n",
      "   [106.5   97.5  124.5 ]\n",
      "   [111.75 102.75 129.75]\n",
      "   ...\n",
      "   [162.25 162.25 186.25]\n",
      "   [166.75 168.75 191.75]\n",
      "   [154.75 156.75 179.75]]\n",
      "\n",
      "  [[113.75 104.75 131.75]\n",
      "   [116.75 107.75 134.75]\n",
      "   [134.5  125.5  152.5 ]\n",
      "   ...\n",
      "   [194.5  194.5  213.25]\n",
      "   [193.   195.   218.  ]\n",
      "   [154.25 156.25 179.25]]\n",
      "\n",
      "  [[117.25 108.25 135.25]\n",
      "   [116.25 107.25 134.25]\n",
      "   [112.25 103.25 130.25]\n",
      "   ...\n",
      "   [163.5  163.5  187.5 ]\n",
      "   [159.75 161.75 184.75]\n",
      "   [174.75 176.75 199.75]]]], shape=(32, 128, 128, 3), dtype=float32) (32, 128, 128, 3)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(32, 38), dtype=float32) (32, 38)\n"
     ]
    }
   ],
   "source": [
    "for x,y in training_set:\n",
    "    print(x,x.shape)\n",
    "    print(y,y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f7e21-0403-442e-9e89-81cc4ff100b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### TO AVOID OVERSHOOTING\n",
    "1. CHOOSE SMALL LEARING RATE DEFAULT 0.001 WE ARE TAKING 0.0001.\n",
    "2. THERE MAY BE CHANCE OF UNDERFITTING,SO INCREASE NUMBER OF NEURON\n",
    "3. ADD MORE CONVOLUTION LAYER TO EXRTRACT MORE FEATURE FROM IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758df92d-489b-4c79-b3be-3c19215f5787",
   "metadata": {},
   "source": [
    "### BUILDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d48397-427f-4001-a6d6-84e6514d7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "946cb4b5-a289-44d5-b6ce-76bf286b9d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8ed1a-83eb-499f-8db6-a2b8045ca0c5",
   "metadata": {},
   "source": [
    "### BUILDING CONVOLUTION LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f77cf3-aa92-458e-b6c9-c1d6163836b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 32,kernel_size = 3,padding = 'same', activation = 'relu', input_shape =[128,128,3]))\n",
    "model.add(Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87538aa2-0d94-4235-95c0-804510aab12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 64,kernel_size = 3,padding = 'same', activation = 'relu', input_shape =[128,128,3]))\n",
    "model.add(Conv2D(filters = 64,kernel_size = 3, activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "789a6a6b-ae4b-4ad4-b1ab-67bc76ec178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 128,kernel_size = 3,padding = 'same', activation = 'relu', input_shape =[128,128,3]))\n",
    "model.add(Conv2D(filters = 128,kernel_size = 3, activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6a43f99-35ac-48d5-9080-2a722381f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 256,kernel_size = 3,padding = 'same', activation = 'relu', input_shape =[128,128,3]))\n",
    "model.add(Conv2D(filters = 256,kernel_size = 3, activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dbaaf35-4cd8-4182-b26a-ec365dee483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 512,kernel_size = 3,padding = 'same', activation = 'relu', input_shape =[128,128,3]))\n",
    "model.add(Conv2D(filters = 512,kernel_size = 3, activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ce8c760-d333-4484-b62f-d75b44ab07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8250483-aa13-4d6f-ba3f-6a928c445a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09292257-d5da-45df-803d-7c6b44e66ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 1500,activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc00f24-2ebc-4005-980b-ebabb00084fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c7d185-a8b9-4ccc-9c8a-f6186a028317",
   "metadata": {},
   "source": [
    "### OUTPUT LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70d6059f-9196-40db-bc7e-b84232a75c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 38,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08f9b8-cde6-4ff1-99fd-4910764f900c",
   "metadata": {},
   "source": [
    "### COMPILING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aef282da-b4e4-48e7-9510-8c2208130542",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer =tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82311f1a-abd0-49f8-a09c-a9c948e134bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 126, 126, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 63, 63, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1500)              3073500   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1500)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 38)                57038     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,842,762\n",
      "Trainable params: 7,842,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561526ef-11a9-471e-ba72-29b160f79c39",
   "metadata": {},
   "source": [
    "### MODEL TRANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5f1611e-094d-45ea-86fd-3d37e2b43755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2197/2197 [==============================] - 328s 143ms/step - loss: 1.3910 - accuracy: 0.5883 - val_loss: 0.5663 - val_accuracy: 0.8209\n",
      "Epoch 2/10\n",
      "2197/2197 [==============================] - 311s 142ms/step - loss: 0.4616 - accuracy: 0.8529 - val_loss: 0.3056 - val_accuracy: 0.9004\n",
      "Epoch 3/10\n",
      "2197/2197 [==============================] - 343s 156ms/step - loss: 0.2723 - accuracy: 0.9133 - val_loss: 0.1767 - val_accuracy: 0.9427\n",
      "Epoch 4/10\n",
      "2197/2197 [==============================] - 310s 141ms/step - loss: 0.1874 - accuracy: 0.9385 - val_loss: 0.1637 - val_accuracy: 0.9474\n",
      "Epoch 5/10\n",
      "2197/2197 [==============================] - 310s 141ms/step - loss: 0.1367 - accuracy: 0.9556 - val_loss: 0.1521 - val_accuracy: 0.9536\n",
      "Epoch 6/10\n",
      "2197/2197 [==============================] - 310s 141ms/step - loss: 0.1083 - accuracy: 0.9640 - val_loss: 0.2220 - val_accuracy: 0.9322\n",
      "Epoch 7/10\n",
      "2197/2197 [==============================] - 536s 244ms/step - loss: 0.0899 - accuracy: 0.9700 - val_loss: 0.1210 - val_accuracy: 0.9616\n",
      "Epoch 8/10\n",
      "2197/2197 [==============================] - 872s 397ms/step - loss: 0.0749 - accuracy: 0.9757 - val_loss: 0.1030 - val_accuracy: 0.9670\n",
      "Epoch 9/10\n",
      "2197/2197 [==============================] - 310s 141ms/step - loss: 0.0637 - accuracy: 0.9794 - val_loss: 0.1509 - val_accuracy: 0.9572\n",
      "Epoch 10/10\n",
      "2197/2197 [==============================] - 1427s 650ms/step - loss: 0.0575 - accuracy: 0.9815 - val_loss: 0.1399 - val_accuracy: 0.9592\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(x=training_set,validation_data=validation_set,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b5362-34d7-4733-81ad-4cbeaa91808a",
   "metadata": {},
   "source": [
    "### MODEL EVALUATION ON TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "447ca57a-80fc-401a-9d44-17e4137f2989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 615/2197 [=======>......................] - ETA: 4:55 - loss: 4.0282 - accuracy: 0.0253 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_loss,train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\AICTE PROJECT\\Tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\AICTE PROJECT\\Tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\AICTE PROJECT\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\AICTE PROJECT\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\AICTE PROJECT\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mD:\\AICTE PROJECT\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\AICTE PROJECT\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\AICTE PROJECT\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mD:\\AICTE PROJECT\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss,train_acc = model.evaluate(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b05bf2-a5e9-4632-859f-85e2e7ac184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loss,train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2323c-653b-45cd-981e-ac1c268c390d",
   "metadata": {},
   "source": [
    "### MODEL EVALUATION ON VALIDATION SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df021ee3-e361-48f8-bc87-7ea7d8c7493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss,val_acc = model.evaluate(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe3b5e6-d292-4e55-b328-40a6346e0ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_loss,val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dd30c5-783a-4a0d-960a-075155f37dfb",
   "metadata": {},
   "source": [
    "### SAVING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c3ef455-c7e9-43cb-bb05-87e2bd858ba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_model()` using h5 format requires h5py. Could not import h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrained_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\AICTE PROJECT\\Tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\AICTE PROJECT\\Tensorflow\\lib\\site-packages\\keras\\saving\\hdf5_format.py:80\u001b[0m, in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Saves a model to a HDF5 file.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03mThe saved model contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    ImportError: if h5py is not available.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`save_model()` using h5 format requires h5py. Could not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport h5py.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# TODO(psv) Add warning when we save models that contain non-serializable\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# entities like metrics added using `add_metric` and losses added using\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# `add_loss.`\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39m_undeduplicated_weights):\n",
      "\u001b[1;31mImportError\u001b[0m: `save_model()` using h5 format requires h5py. Could not import h5py."
     ]
    }
   ],
   "source": [
    "model.save('trained_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08b3dc-35ab-4c80-99d7-bcdc4ba1fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c3ac05-dd95-4d74-ae41-6093647cfc54",
   "metadata": {},
   "source": [
    "### RECORDING HISTORY IN JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e98c86-553b-4356-b514-f3989f54c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open (\"training_hist.json\",\"w\") as f:\n",
    "    json.dump(training_history.history,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e92b9-e144-4d89-8bde-f864b102597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967b91a-fe35-4c5a-a57b-07e126711749",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51275b0d-1831-44f2-b264-20c4503789c6",
   "metadata": {},
   "source": [
    "### ACCURACY VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7076b8-ad3c-4ab5-a799-5dd9f558d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(1,11)]\n",
    "plt.plot(epochs,training_history.history['accuracy'],color = 'red', label = 'Training Accuracy')\n",
    "plt.plot(epochs,training_history.history['val_accuracy'],color = 'blue', label = 'Validation Accuracy')\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy Result\")\n",
    "plt.title(\"Visualiztion of Accuracy Result\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b97f0e-e7c8-411b-b8cd-0d58c9362d8b",
   "metadata": {},
   "source": [
    "### SOME OTHER METRIC FOR MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641eda1-d682-456f-a8b4-bc040ce48898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = validation_set.class_names\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127942f3-a553-4314-b6ab-11b33a5b03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06476a49-cf2a-475f-ae6f-2ca5340c49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_set)\n",
    "y_pred,y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ae828-c5d9-454d-9f1e-26c90313f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_categories = tf.argmax(y_pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5128a58-74f2-46c3-b328-ebe2b5a5a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d02c04-497e-4d42-9a18-a0783852c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_categories = tf.concat([y for x,y in test_set], axis = 0)\n",
    "true_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe41b3-2fde-4a27-a8f8-7f70d931da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true = tf.argmax(true_categories,axis = 1)\n",
    "Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7740e3-042f-45f3-a8ac-9b418ce48f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c6d59-84b7-482c-8b1a-4535a339b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_true,predicted_categories,target_names = class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae8f6e-060d-434e-832b-0e6a02734904",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_true,predicted_categories)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd54fab-a75e-4f7b-bf46-0850194397f5",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d47bd7-92d4-43f5-96d9-36d15ccfc448",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(cm, annot=True, annot_kws={'size': 10})\n",
    "plt.xlabel(\"Predicted Class\",fontsize = 20)\n",
    "plt.ylabel(\"Actual Class\",fontsize = 20)\n",
    "plt.title(\"Plant Disease Prediction Confusion Matrix\",fontsize = 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d25c8-0048-4f8c-98de-a16ca07d90c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018fdb7f-d54e-4ad4-be98-604699f43f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
